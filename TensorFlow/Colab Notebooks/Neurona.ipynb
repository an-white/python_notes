{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Neurona.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNf2zxjucGwfacqOvwMCZGH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"OgobJ2ZAi_n5"},"source":["**bias o sesgo**\n","Permite desplazar la curva en alguna direccion para que el valor de esta suma no sea 0\n","\n","Los pesos de la regresion lineal son variado aleatoreamente por el perceptron\n","\n","**Funcion de activacion**\n","Permite distorcionar la salida del la funcion de suma ponderada\n","\n","A mayor numero de neuronas mejor sera prediccion de la red neuronal\n","pero puede sufrir de sobreajuste\n","\n","Arquitectura de Red Neuronal\n","Esta estructurado en layers cada layer va a pasar informacion al siguiente lo cual hace que a medida que la informacion vaya de layer en layer la informacion sera mas mucho mas compleja y facil de procesar por el siguiente layer, a mayor cantidad de layers la informacion sera mas precisa\n","\n","# **Estructura**\n","\n","**Capa de entrada / input layer**\n","Datos de entrada\n","\n","**Capas ocultas / hidden layers**\n","las primeras tendran informacion muy generica y las ultimas seran mucho mas precisas lo que se debe evaluar para no provocar overfitting\n","\n","**Capa de salida / Output layer**\n","se encarga de predecir o clasificar segun sea su proposito\n","\n","**Vectores**\n","Dentro de la arquitectura de la red neuronal ocurren muchas operaciones de producto punto entre las entradas de cada perceptron con sus respectivos pesos. Estas operaciones son lineales.\n","\n","Las funciones de activación son la solución al colapso de las linealidades de las capas de la red neuronal."]}]}